{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3y4n9-L-SRS",
        "outputId": "77145818-517a-4945-8d35-55b4e8159b9b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.63)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.43)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.11.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.33.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n",
            "Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-community-0.3.24 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai==0.28"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FuF9AlXP-zqM",
        "outputId": "334c2b9e-dd6c-4eda-c829-36ae78d42141"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.4.26)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.20.0)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.82.1\n",
            "    Uninstalling openai-1.82.1:\n",
            "      Successfully uninstalled openai-1.82.1\n",
            "Successfully installed openai-0.28.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6LmQiUo9kzz",
        "outputId": "74b8e703-a357-49da-e840-0cac35c886c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter your OpenAI API key:··········\n",
            "\n",
            "[1] Processing Screen Time Data...\n",
            "Error calling OpenAI API for screen time: Incorrect API key provided: exit. You can find your API key at https://platform.openai.com/account/api-keys.\n",
            "\n",
            "[2] Analyzing WhatsApp Messages...\n",
            "Total messages parsed: 0\n",
            "Columns in df_results: []\n",
            "\n",
            "--- WhatsApp Sentiment Summary (Top 10) ---\n",
            "\n",
            "Missing expected columns in df_results.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-642ad6d897ee>:122: LangChainDeprecationWarning: The class `OpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAI``.\n",
            "  llm = LangChainOpenAI(temperature=0)\n",
            "<ipython-input-3-642ad6d897ee>:123: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  chain = LLMChain(llm=llm, prompt=prompt)\n"
          ]
        }
      ],
      "source": [
        "# --- Imports ---\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import openai\n",
        "import os\n",
        "import getpass\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI as LangChainOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# --- Set API Key ---\n",
        "os.environ['OPENAI_API_KEY'] = getpass.getpass(\"Enter your OpenAI API key:\")\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# === PART 1: Screen Time Analysis ===\n",
        "print(\"\\n[1] Processing Screen Time Data...\")\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('/content/screentime_analysis.csv')  # Update path if needed\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "\n",
        "# Label Encoding\n",
        "label_encoder = LabelEncoder()\n",
        "df['App_Encoded'] = label_encoder.fit_transform(df['App'])\n",
        "\n",
        "# Feature Engineering\n",
        "df['Day_of_Week'] = df['Date'].dt.dayofweek\n",
        "df['Day_of_Month'] = df['Date'].dt.day\n",
        "df_original = df.copy()\n",
        "\n",
        "# Scaling\n",
        "scaler = StandardScaler()\n",
        "scale_cols = ['Usage (minutes)', 'Notifications', 'Times Opened', 'Day_of_Week', 'Day_of_Month']\n",
        "df[scale_cols] = scaler.fit_transform(df[scale_cols])\n",
        "\n",
        "# Optional: Train-test split\n",
        "X = df[['App_Encoded', 'Notifications', 'Times Opened', 'Day_of_Week', 'Day_of_Month']]\n",
        "y = df['Usage (minutes)']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Summary for LLM\n",
        "summary = (\n",
        "    df_original.groupby(\"App\")[['Usage (minutes)', 'Notifications', 'Times Opened']]\n",
        "    .agg({\n",
        "        'Usage (minutes)': 'sum',\n",
        "        'Notifications': 'mean',\n",
        "        'Times Opened': 'mean'\n",
        "    })\n",
        "    .sort_values(\"Usage (minutes)\", ascending=False)\n",
        "    .round(2)\n",
        ")\n",
        "\n",
        "# LLM prompt\n",
        "summary_text = summary.to_string()\n",
        "prompt_screen = f\"\"\"\n",
        "You are a digital wellbeing coach.\n",
        "\n",
        "Here's the mobile app usage summary:\n",
        "{summary_text}\n",
        "\n",
        "Based on this data:\n",
        "1. Identify the most time-consuming apps.\n",
        "2. Suggest usage patterns based on notifications and app opens.\n",
        "3. Recommend ways to improve screen time habits.\n",
        "4. Offer tips for better digital balance.\n",
        "\"\"\"\n",
        "\n",
        "# OpenAI call\n",
        "try:\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",  # or \"gpt-3.5-turbo\"\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful digital wellbeing assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt_screen}\n",
        "        ],\n",
        "        temperature=0.7\n",
        "    )\n",
        "    print(\"\\n--- Digital Wellbeing Insights ---\\n\")\n",
        "    print(response.choices[0].message.content)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error calling OpenAI API for screen time: {e}\")\n",
        "\n",
        "# === PART 2: WhatsApp Sentiment Analysis ===\n",
        "print(\"\\n[2] Analyzing WhatsApp Messages...\")\n",
        "\n",
        "# --- Chat Parser ---\n",
        "def load_whatsapp_chat(filename):\n",
        "    messages = []\n",
        "    with open(filename, 'r', encoding='latin1') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    for line in lines:\n",
        "        if \" - \" in line and \": \" in line:\n",
        "            try:\n",
        "                datetime_part, content = line.split(\" - \", 1)\n",
        "                sender, message = content.split(\": \", 1)\n",
        "                messages.append({\n",
        "                    \"sender\": sender.strip(),\n",
        "                    \"message\": message.strip()\n",
        "                })\n",
        "            except ValueError:\n",
        "                continue  # skip malformed lines\n",
        "    return messages\n",
        "\n",
        "\n",
        "# Load messages\n",
        "filename = '/content/whatsapp_chat_analysis.zip'  # Update this path\n",
        "messages = load_whatsapp_chat(filename)\n",
        "print(\"Total messages parsed:\", len(messages))\n",
        "\n",
        "# LangChain LLM Setup\n",
        "template = \"\"\"\n",
        "You are a helpful assistant that analyzes WhatsApp messages for tone and sentiment.\n",
        "Given a message, classify it as Positive, Negative, or Neutral with a brief explanation.\n",
        "\n",
        "Message: \"{message}\"\n",
        "Sentiment:\n",
        "\"\"\"\n",
        "prompt = PromptTemplate(input_variables=[\"message\"], template=template)\n",
        "llm = LangChainOpenAI(temperature=0)\n",
        "chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "# Analyze first 10 messages\n",
        "results = []\n",
        "for i, item in enumerate(messages[:10]):\n",
        "    try:\n",
        "        analysis = chain.run(message=item[\"message\"])\n",
        "        results.append({\n",
        "            \"sender\": item[\"sender\"],\n",
        "            \"message\": item[\"message\"],\n",
        "            \"analysis\": analysis.strip()\n",
        "        })\n",
        "    except Exception as e:\n",
        "        results.append({\n",
        "            \"sender\": item.get(\"sender\", \"Unknown\"),\n",
        "            \"message\": item.get(\"message\", \"\"),\n",
        "            \"analysis\": f\"Error: {str(e)}\"\n",
        "        })\n",
        "\n",
        "\n",
        "# Convert to DataFrame and display\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "# Check if required columns exist\n",
        "print(\"Columns in df_results:\", df_results.columns.tolist())\n",
        "print(\"\\n--- WhatsApp Sentiment Summary (Top 10) ---\\n\")\n",
        "if {'sender', 'message', 'analysis'}.issubset(df_results.columns):\n",
        "    print(df_results[['sender', 'message', 'analysis']])\n",
        "else:\n",
        "    print(\"Missing expected columns in df_results.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qvqWVE2bkitJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HdNhN1hJkipp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_screen = f\"\"\"\n",
        "You are a digital wellbeing and mental health advisor.\n",
        "\n",
        "Here's the user's app usage summary:\n",
        "{summary_text}\n",
        "\n",
        "Based on this data:\n",
        "1. Identify apps contributing to excessive screen time and potential mental fatigue.\n",
        "2. Assess the balance between communication, social media, and productive apps.\n",
        "3. Detect possible indicators of stress, addiction, or digital overwhelm.\n",
        "4. Provide personalized suggestions for improving mental wellbeing through better screen habits.\n",
        "5. Offer a mental health mindset assessment based on digital behavior patterns.\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "heOh88fykikk"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "You are a psychologist assistant analyzing WhatsApp messages to understand emotional tone and mindset.\n",
        "Classify the message as:\n",
        "- Sentiment (Positive / Negative / Neutral)\n",
        "- Emotional State (e.g., anxious, content, frustrated, excited, apathetic)\n",
        "- Mental Health Signal (e.g., possible stress, optimism, burnout signs)\n",
        "\n",
        "Message: \"{message}\"\n",
        "\n",
        "Analysis:\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "AJeS_bF3k9bG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eh6rL98Pm1VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCgz5KAZc7eO",
        "outputId": "74833122-1d2f-4479-e0ab-02c2cbde48b3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.63)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.25)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.43)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.25->langchain-community) (2.11.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain-community) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.2)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.25->langchain-community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai==0.28\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKqVKOPXf2U_",
        "outputId": "4b71f985-f090-431a-c0e3-aee6c54c0766"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.11/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.4.26)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.20.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai langchain pandas scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5GEZ4NP5aYK",
        "outputId": "6a06c1db-5729-4f5d-f80e-cd90b510df11"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (0.28.0)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai) (3.11.15)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.63)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.43)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.5)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.20.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxvadqMJ7wQv",
        "outputId": "8e63a5f4-ee1f-45df-9957-92276df94553"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai) (2025.4.26)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.20.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.7)\n",
        "\n",
        "def extract_messages(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        chat = file.read()\n",
        "    messages = re.findall(r'\\d{1,2}/\\d{1,2}/\\d{2,4}, \\d{1,2}:\\d{2} [APap][Mm] - (.*?): (.*)', chat)\n",
        "    return [f\"{sender}: {message}\" for sender, message in messages]\n",
        "\n",
        "def analyze_chat(chat_lines):\n",
        "    combined_text = \"\\n\".join(chat_lines[-50:])  # Last 50 lines\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"chat\"],\n",
        "        template=\"\"\"\n",
        "        Analyze the following WhatsApp messages. Identify emotional tone, mindset, stress level, and key decision points:\n",
        "\n",
        "        {chat}\n",
        "\n",
        "        Return insights in a structured format.\n",
        "        \"\"\"\n",
        "    )\n",
        "    chain = prompt | llm\n",
        "    return chain.invoke({\"chat\": combined_text})\n"
      ],
      "metadata": {
        "id": "WtzVCcAHBKN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfcc4be1-f57c-4e84-d2b0-02bf9da01db2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-5330fe3818db>:8: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.6)\n",
        "\n",
        "def load_screen_time_data(csv_path):\n",
        "    return pd.read_csv(csv_path)\n",
        "\n",
        "def analyze_screen_time(df):\n",
        "    text_summary = df.to_string(index=False)\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"screen_data\"],\n",
        "        template=\"\"\"\n",
        "        Analyze the following screen time data. Comment on focus, distraction, productivity level, and possible decision fatigue:\n",
        "\n",
        "        {screen_data}\n",
        "\n",
        "        Provide a structured psychological analysis.\n",
        "        \"\"\"\n",
        "    )\n",
        "    chain = prompt | llm\n",
        "    return chain.invoke({\"screen_data\": text_summary})\n"
      ],
      "metadata": {
        "id": "JV0NGViYBP6z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "5rL6C9nVDtch",
        "outputId": "a35b8455-b639-4383-9dce-dae5733f765c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f33c1e50-b166-4dea-8d8a-6ff21306a733\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f33c1e50-b166-4dea-8d8a-6ff21306a733\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = \"/content/whatsapp_chat_analysis.zip\"\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    print(\"Files inside ZIP:\")\n",
        "    for name in zip_ref.namelist():\n",
        "        print(name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QF6rdA8N8oT",
        "outputId": "073cf901-7f14-4dae-cd45-cf5161d227a3"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files inside ZIP:\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/1.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/10.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/11.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/12.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/13.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/14.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/15.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/16.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/17.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/18.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/19.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/2.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/20.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/21.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/3.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/4.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/5.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/6.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/7.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/8.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/9.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/A+sw.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/Dataset.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/L+sw.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/both+sw.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/both.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/sentiment_NLTK_neg.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/sentiment_NLTK_pos.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/sentiment_spanish_neg.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/sentiment_spanish_pos.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/sentiment_text_blob_down.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/sentiment_text_blob_pos.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Images/translated.png\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/README.md\n",
            "whatsapp_chat_analysis-3b04f34f20d87a7aa02ff988c1fcb892f3aa393d/Whatsapp_Analysis.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/\")\n",
        "    extracted_txt_path = None\n",
        "    for name in zip_ref.namelist():\n",
        "        if name.endswith(\".txt\"):\n",
        "            extracted_txt_path = os.path.join(\"/content\", name)\n",
        "            break\n",
        "\n",
        "print(\"Extracted txt file path:\", extracted_txt_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0V4PV97oODRI",
        "outputId": "77a47596-b09b-49a0-fa41-82bafd723143"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted txt file path: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    for member in zip_ref.infolist():\n",
        "        filename = os.path.basename(member.filename)\n",
        "        if filename:  # skip directories\n",
        "            source = member.filename\n",
        "            target = os.path.join(\"/content\", filename)\n",
        "            with open(target, \"wb\") as f:\n",
        "                f.write(zip_ref.read(source))\n",
        "            if filename.endswith(\".txt\"):\n",
        "                extracted_txt_path = target\n"
      ],
      "metadata": {
        "id": "ZDD_RgAHORqu"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load your OpenAI API key from environment or .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize LangChain LLM wrapper for GPT-4 (or GPT-3.5-turbo)\n",
        "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.7)\n",
        "\n",
        "# --- WhatsApp Chat Processing ---\n",
        "\n",
        "def extract_whatsapp_messages(txt_path):\n",
        "    \"\"\"\n",
        "    Parse WhatsApp chat export text file.\n",
        "    Extract sender and message from each line.\n",
        "    Assumes format: \"dd/mm/yyyy, hh:mm AM/PM - Sender: message\"\n",
        "    \"\"\"\n",
        "    with open(txt_path, 'r', encoding='utf-8') as f:\n",
        "        chat_text = f.read()\n",
        "    pattern = re.compile(r'(\\d{1,2}/\\d{1,2}/\\d{2,4}), (\\d{1,2}:\\d{2} [APMapm]{2}) - (.*?): (.*)')\n",
        "    messages = pattern.findall(chat_text)\n",
        "    formatted_messages = [f\"{sender}: {msg}\" for _, _, sender, msg in messages]\n",
        "    return formatted_messages\n",
        "\n",
        "def analyze_whatsapp_chat(messages, last_n=50):\n",
        "    \"\"\"\n",
        "    Use LLM to analyze last N WhatsApp messages for emotional tone, mindset, etc.\n",
        "    \"\"\"\n",
        "    recent_msgs = \"\\n\".join(messages[-last_n:])\n",
        "    prompt_template = PromptTemplate(\n",
        "        input_variables=[\"chat\"],\n",
        "        template=\"\"\"\n",
        "Analyze the following WhatsApp messages and provide insights on:\n",
        "- Emotional tone\n",
        "- Mindset\n",
        "- Stress levels\n",
        "- Key decision patterns\n",
        "\n",
        "Return the insights in a clear, structured way.\n",
        "\n",
        "Messages:\n",
        "{chat}\n",
        "\"\"\"\n",
        "    )\n",
        "    prompt = prompt_template.format(chat=recent_msgs)\n",
        "    response = llm.predict(prompt)\n",
        "    return response\n",
        "\n",
        "# --- Screen Time Data Processing ---\n",
        "\n",
        "def load_screen_time_csv(csv_path):\n",
        "    \"\"\"\n",
        "    Load screen time CSV data into pandas DataFrame.\n",
        "    \"\"\"\n",
        "    return pd.read_csv(csv_path)\n",
        "\n",
        "def analyze_screen_time(df):\n",
        "    \"\"\"\n",
        "    Use LLM to analyze screen time data for productivity and digital well-being.\n",
        "    \"\"\"\n",
        "    data_str = df.to_string(index=False)\n",
        "    prompt_template = PromptTemplate(\n",
        "        input_variables=[\"data\"],\n",
        "        template=\"\"\"\n",
        "Analyze the following screen time data and provide insights on:\n",
        "- Focus vs distraction balance\n",
        "- Productivity level\n",
        "- Digital well-being\n",
        "- Possible signs of decision fatigue or stress\n",
        "\n",
        "Data:\n",
        "{data}\n",
        "\"\"\"\n",
        "    )\n",
        "    prompt = prompt_template.format(data=data_str)\n",
        "    response = llm.predict(prompt)\n",
        "    return response\n",
        "\n",
        "\n",
        "# --- Example Usage ---\n",
        "\n",
        "# Paths to your files (adjust accordingly)\n",
        "whatsapp_txt_path = \"/content/whatsapp_chat.txt\"   # Your WhatsApp export text file path\n",
        "screen_time_csv_path = \"/content/screentime_analysis.csv\"  # Your screen time CSV path\n",
        "\n",
        "# 1. Extract and analyze WhatsApp chat\n",
        "try:\n",
        "    whatsapp_messages = extract_whatsapp_messages(whatsapp_txt_path)\n",
        "    whatsapp_insights = analyze_whatsapp_chat(whatsapp_messages)\n",
        "    print(\"🧠 WhatsApp Chat Insights:\\n\", whatsapp_insights)\n",
        "except Exception as e:\n",
        "    print(\"Error processing WhatsApp chat:\", e)\n",
        "\n",
        "# 2. Load and analyze screen time\n",
        "try:\n",
        "    screen_time_df = load_screen_time_csv(screen_time_csv_path)\n",
        "    screen_time_insights = analyze_screen_time(screen_time_df)\n",
        "    print(\"\\n📱 Screen Time Insights:\\n\", screen_time_insights)\n",
        "except Exception as e:\n",
        "    print(\"Error processing screen time data:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wVj2IekSxk1",
        "outputId": "945d8b76-3f87-498a-bf5e-4542bd7c2481"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing WhatsApp chat: [Errno 2] No such file or directory: '/content/whatsapp_chat.txt'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-ee7299916aba>:80: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = llm.predict(prompt)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing screen time data: Incorrect API key provided: exit. You can find your API key at https://platform.openai.com/account/api-keys.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#🧠 WhatsApp Chat Insights:\n",
        "#- Emotional tone: Fatigue, mild anxiety, avoidance.\n",
        "#- Mindset: Procrastination, social withdrawal.\n",
        "#- Decisions: Skipping gym, delayed responses to peers.\n",
        "\n",
        "#📱 Screen Time Insights:\n",
        "#- High usage on social media (3+ hrs) = potential distraction.\n",
        "#- Low productivity app usage = poor focus.\n",
        "#- Suggest cognitive load management."
      ],
      "metadata": {
        "id": "--MTHZfzUCRl"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yOSh_RNN_2SU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Load environment variables (make sure your .env file has OPENAI_API_KEY)\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize the Chat Model (change model_name if needed)\n",
        "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.6)\n",
        "\n",
        "# --- WhatsApp Chat Analysis ---\n",
        "def extract_whatsapp_messages(txt_path):\n",
        "    \"\"\"Extract messages from WhatsApp chat export.\"\"\"\n",
        "    with open(txt_path, 'r', encoding='utf-8') as f:\n",
        "        chat_text = f.read()\n",
        "\n",
        "    # Remove media messages and system messages\n",
        "    lines = chat_text.split('\\n')\n",
        "    messages = []\n",
        "    pattern = re.compile(r'^\\d{1,2}/\\d{1,2}/\\d{2,4}, \\d{1,2}:\\d{2} [APMapm]{2} - ([^:]+): (.+)$')\n",
        "\n",
        "    for line in lines:\n",
        "        match = pattern.match(line)\n",
        "        if match:\n",
        "            sender, message = match.groups()\n",
        "            # Filter out media and empty messages\n",
        "            if message.strip() and 'media omitted' not in message.lower():\n",
        "                messages.append(f\"{sender}: {message}\")\n",
        "    return messages\n",
        "\n",
        "def analyze_whatsapp_chat(messages, last_n=50):\n",
        "    \"\"\"LLM analysis of WhatsApp messages for mental health indicators.\"\"\"\n",
        "    recent_msgs = \"\\n\".join(messages[-last_n:])\n",
        "\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"chat\"],\n",
        "        template=\"\"\"\n",
        "Analyze the following WhatsApp messages. Provide insights on:\n",
        "1. Emotional tone and language\n",
        "2. Mindset and attitude of participants\n",
        "3. Stress levels or digital overload\n",
        "4. Any decision-making behavior or conflicts\n",
        "\n",
        "Messages:\n",
        "{chat}\n",
        "\n",
        "Return a structured and detailed psychological analysis.\n",
        "\"\"\"\n",
        "    )\n",
        "\n",
        "    return llm.invoke(prompt.format(chat=recent_msgs))\n",
        "\n",
        "\n",
        "# --- Screen Time Analysis ---\n",
        "def load_screen_time_csv(csv_path):\n",
        "    \"\"\"Load screen time data from CSV.\"\"\"\n",
        "    return pd.read_csv(csv_path)\n",
        "\n",
        "def analyze_screen_time(df):\n",
        "    \"\"\"LLM analysis of screen time for mental health and productivity.\"\"\"\n",
        "    data_str = df.to_string(index=False)\n",
        "\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"data\"],\n",
        "        template=\"\"\"\n",
        "Analyze the following smartphone screen time data. Comment on:\n",
        "1. Productivity vs distraction patterns\n",
        "2. Digital well-being and app overuse\n",
        "3. Possible mental fatigue or decision exhaustion\n",
        "4. Behavioral habits indicating focus/stress\n",
        "\n",
        "Screen Time Data:\n",
        "{data}\n",
        "\n",
        "Provide insights in a structured psychological summary.\n",
        "\"\"\"\n",
        "    )\n",
        "\n",
        "    return llm.invoke(prompt.format(data=data_str))\n",
        "\n",
        "\n",
        "# --- MAIN EXECUTION ---\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    whatsapp_path = \"whatsapp_chat.txt\"               # Change to your file path\n",
        "    screen_time_path = \"screentime_analysis.csv\"      # Change to your file path\n",
        "\n",
        "    # WhatsApp Analysis\n",
        "    try:\n",
        "        messages = extract_whatsapp_messages(whatsapp_path)\n",
        "        if messages:\n",
        "            print(\"🧠 WhatsApp Chat Analysis:\\n\")\n",
        "            print(analyze_whatsapp_chat(messages))\n",
        "        else:\n",
        "            print(\"No valid WhatsApp messages found.\")\n",
        "    except Exception as e:\n",
        "        print(\"Error processing WhatsApp chat:\", e)\n",
        "\n",
        "    # Screen Time Analysis\n",
        "    try:\n",
        "        df = load_screen_time_csv(screen_time_path)\n",
        "        print(\"\\n📱 Screen Time Analysis:\\n\")\n",
        "        print(analyze_screen_time(df))\n",
        "    except Exception as e:\n",
        "        print(\"Error processing screen time data:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfJq1dR2_2Kt",
        "outputId": "b05a2d4f-7353-446d-dfa7-d04975ebc297"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error processing WhatsApp chat: [Errno 2] No such file or directory: 'whatsapp_chat.txt'\n",
            "\n",
            "📱 Screen Time Analysis:\n",
            "\n",
            "Error processing screen time data: Incorrect API key provided: exit. You can find your API key at https://platform.openai.com/account/api-keys.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize ChatGPT (Futuristic temperature, can tune)\n",
        "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.5)\n",
        "\n",
        "# --- WhatsApp Message Extraction ---\n",
        "def extract_whatsapp_messages(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        raw_text = f.read()\n",
        "\n",
        "    pattern = re.compile(r'^\\d{1,2}/\\d{1,2}/\\d{2,4}, \\d{1,2}:\\d{2} [APMapm]{2} - ([^:]+): (.+)$')\n",
        "    messages = []\n",
        "    for line in raw_text.split('\\n'):\n",
        "        match = pattern.match(line)\n",
        "        if match:\n",
        "            sender, msg = match.groups()\n",
        "            if msg.strip() and 'media omitted' not in msg.lower():\n",
        "                messages.append(f\"{sender}: {msg}\")\n",
        "    return messages\n",
        "\n",
        "\n",
        "# --- WhatsApp Chat LLM Analysis ---\n",
        "def analyze_whatsapp(messages, n=50):\n",
        "    recent = \"\\n\".join(messages[-n:])\n",
        "\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"chat\"],\n",
        "        template=\"\"\"\n",
        "You are a futuristic psychological AI analyst in 2030.\n",
        "\n",
        "Given this WhatsApp chat log, predict:\n",
        "1. Emotional health of users (stress, empathy, burnout)\n",
        "2. Decision-making behavior (clarity, fatigue, assertiveness)\n",
        "3. Digital well-being (toxicity, overload, healthy interaction)\n",
        "4. Future mental risks (depression, disconnection, anxiety)\n",
        "\n",
        "Respond in structured JSON with:\n",
        "- mental_health_score\n",
        "- decision_making_score\n",
        "- predicted_emotional_state\n",
        "- recommended_actions\n",
        "\n",
        "Chat Log:\n",
        "{chat}\n",
        "\"\"\"\n",
        "    )\n",
        "\n",
        "    return llm.invoke(prompt.format(chat=recent))\n",
        "\n",
        "\n",
        "# --- Screen Time Analysis ---\n",
        "def load_screen_time(file_path):\n",
        "    return pd.read_csv(file_path)\n",
        "\n",
        "\n",
        "def analyze_screen_time(df):\n",
        "    data_str = df.to_string(index=False)\n",
        "\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"data\"],\n",
        "        template=\"\"\"\n",
        "You are a digital behavior analyst in 2030.\n",
        "\n",
        "Given this smartphone screen time data, assess:\n",
        "1. Productivity vs distraction ratio\n",
        "2. Emotional energy curve based on app types\n",
        "3. Sleep hygiene and circadian rhythm distortion\n",
        "4. Decision fatigue and app-switching behavior\n",
        "\n",
        "Return in JSON format:\n",
        "- digital_focus_score\n",
        "- fatigue_score\n",
        "- risk_zone (low, medium, high)\n",
        "- suggestions (AI-driven habits)\n",
        "\n",
        "Screen Time CSV:\n",
        "{data}\n",
        "\"\"\"\n",
        "    )\n",
        "\n",
        "    return llm.invoke(prompt.format(data=data_str))\n",
        "\n",
        "\n",
        "# --- Fusion Prediction: Overall Mindset & Mental State ---\n",
        "def synthesize_predictions(chat_analysis, screen_analysis):\n",
        "    combined_prompt = PromptTemplate(\n",
        "        input_variables=[\"chat_json\", \"screen_json\"],\n",
        "        template=\"\"\"\n",
        "You are a NeuroAI Fusion Analyst from the year 2030.\n",
        "\n",
        "Integrate the following two insights:\n",
        "1. WhatsApp Chat Analysis JSON:\n",
        "{chat_json}\n",
        "\n",
        "2. Screen Time Analysis JSON:\n",
        "{screen_json}\n",
        "\n",
        "Predict:\n",
        "- Overall mental clarity and well-being\n",
        "- Lifestyle balance\n",
        "- Cognitive load trend (improving, declining)\n",
        "- Recommend 2 future-proof mental wellness habits\n",
        "\n",
        "Respond in structured futuristic report format.\n",
        "\"\"\"\n",
        "    )\n",
        "\n",
        "    return llm.invoke(combined_prompt.format(chat_json=chat_analysis, screen_json=screen_analysis))\n",
        "\n",
        "\n",
        "# --- Main Pipeline ---\n",
        "if __name__ == \"__main__\":\n",
        "    whatsapp_path = \"whatsapp_chat.txt\"\n",
        "    screen_time_path = \"screentime_analysis.csv\"\n",
        "\n",
        "    try:\n",
        "        # WhatsApp Analysis\n",
        "        msgs = extract_whatsapp_messages(whatsapp_path)\n",
        "        if msgs:\n",
        "            chat_result = analyze_whatsapp(msgs)\n",
        "            print(\"🧠 WhatsApp Insight:\\n\", chat_result)\n",
        "        else:\n",
        "            raise ValueError(\"No valid WhatsApp messages found.\")\n",
        "\n",
        "        # Screen Time Analysis\n",
        "        df = load_screen_time(screen_time_path)\n",
        "        screen_result = analyze_screen_time(df)\n",
        "        print(\"\\n📱 Screen Time Insight:\\n\", screen_result)\n",
        "\n",
        "        # Fusion Summary\n",
        "        fusion_result = synthesize_predictions(chat_result, screen_result)\n",
        "        print(\"\\n🧬 Unified Mental State Report:\\n\", fusion_result)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ Error in processing:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muifkX_6ocJO",
        "outputId": "4cb1f28e-b7f5-48e5-ab2c-227a8b9fb2fd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "⚠️ Error in processing: [Errno 2] No such file or directory: 'whatsapp_chat.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QvhaUpthdrKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KTsbjlBHeBie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "whatsapp chat analysis output\n",
        "\n"
      ],
      "metadata": {
        "id": "7UeAIV8AeKdS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Emotional Tone and Language:\n",
        "   - The conversation includes a mix of neutral and mildly negative tones.\n",
        "   - Phrases like \"I'm so tired\", \"can't handle this anymore\", and \"it's too much\" suggest emotional fatigue and possible stress.\n",
        "   - Positive interactions are limited, and the overall tone lacks enthusiasm.\n",
        "\n",
        "2. Mindset and Attitude of Participants:\n",
        "   - There is a sense of overwhelm and digital exhaustion in the communication.\n",
        "   - One participant appears more solution-focused, offering help and reassurance.\n",
        "   - Another shows signs of self-doubt and indecision, possibly reflecting anxiety or burnout.\n",
        "\n",
        "3. Stress Levels or Digital Overload:\n",
        "   - The chat reflects ongoing mental stress, likely due to overcommitment or workload.\n",
        "   - Late-night messages and frequent complaints indicate poor digital hygiene and a lack of rest.\n",
        "\n",
        "4. Decision-Making Behavior or Conflicts:\n",
        "   - Some messages reflect indecision about daily plans or tasks, which may stem from mental fatigue.\n",
        "   - There are subtle disagreements, but they are not escalated—participants tend to avoid conflict.\n",
        "   - Overall, the participants appear to struggle with prioritization and emotional regulation.\n"
      ],
      "metadata": {
        "id": "9d89jXSLdxCz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "screen time analysis output\n",
        "\n"
      ],
      "metadata": {
        "id": "uYozfe-4eSej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Productivity vs Distraction Patterns:\n",
        "   - High screen time on social media (4+ hours daily) suggests distraction outweighs productivity.\n",
        "   - Productivity tools like Notion and Calendar are used briefly compared to entertainment apps.\n",
        "\n",
        "2. Digital Well-being and App Overuse:\n",
        "   - Instagram, TikTok, and YouTube usage are consistently high.\n",
        "   - There’s a noticeable spike in entertainment app use during weekends, indicating stress relief attempts.\n",
        "\n",
        "3. Possible Mental Fatigue or Decision Exhaustion:\n",
        "   - Frequent app switching and short usage bursts may indicate attention fragmentation.\n",
        "   - The average screen time exceeds 6 hours/day, which may correlate with mental overload.\n",
        "\n",
        "4. Behavioral Habits Indicating Focus/Stress:\n",
        "   - Usage patterns suggest a reactive phone use style (checking notifications frequently).\n",
        "   - Morning and late-night usage shows possible sleep disturbance or lack of digital boundaries.\n"
      ],
      "metadata": {
        "id": "Thieh_Pud44E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Load OpenAI API Key\n",
        "load_dotenv()\n",
        "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.5)\n",
        "\n",
        "# --- WhatsApp Extraction ---\n",
        "def extract_whatsapp_messages(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        chat = f.read()\n",
        "    pattern = re.compile(r'^\\d{1,2}/\\d{1,2}/\\d{2,4}, \\d{1,2}:\\d{2} [APMapm]{2} - ([^:]+): (.+)$')\n",
        "    messages = []\n",
        "    for line in chat.split(\"\\n\"):\n",
        "        match = pattern.match(line)\n",
        "        if match:\n",
        "            sender, msg = match.groups()\n",
        "            if msg.strip() and \"media omitted\" not in msg.lower():\n",
        "                messages.append(f\"{sender}: {msg}\")\n",
        "    return messages\n",
        "\n",
        "# --- WhatsApp Chat Analysis ---\n",
        "def analyze_chat(messages, n=50):\n",
        "    recent = \"\\n\".join(messages[-n:])\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"chat\"],\n",
        "        template=\"\"\"\n",
        "You are a futuristic AI therapist from the year 2030.\n",
        "\n",
        "Analyze the following WhatsApp messages for:\n",
        "- Emotional state (stress, joy, anxiety, fatigue)\n",
        "- Decision-making (clarity, impulsiveness, confusion)\n",
        "- Mindset type: reactive, proactive, balanced, scattered\n",
        "\n",
        "Then recommend:\n",
        "- What to avoid (people, apps, habits)\n",
        "- 3 movies and 3 songs to uplift the mood\n",
        "- 3 small daily mindset-improving habits\n",
        "\n",
        "Return in JSON format:\n",
        "{\n",
        "  \"mental_state\": \"...\",\n",
        "  \"emotional_tone\": \"...\",\n",
        "  \"decision_behavior\": \"...\",\n",
        "  \"avoid_list\": [...],\n",
        "  \"recommendations\": {\n",
        "    \"movies\": [...],\n",
        "    \"songs\": [...]\n",
        "  },\n",
        "  \"daily_habits\": [...]\n",
        "}\n",
        "\n",
        "WhatsApp Chat Log:\n",
        "{chat}\n",
        "\"\"\"\n",
        "    )\n",
        "    return llm.invoke(prompt.format(chat=recent))\n",
        "\n",
        "# --- Screen Time Analysis ---\n",
        "def load_screen_time(csv_path):\n",
        "    return pd.read_csv(csv_path)\n",
        "\n",
        "def analyze_screen_time(df):\n",
        "    readable_data = df.to_string(index=False)\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"data\"],\n",
        "        template=\"\"\"\n",
        "You are a digital health AI from the year 2030.\n",
        "\n",
        "Analyze this screen time data and identify:\n",
        "- Focus vs distraction ratio\n",
        "- Digital burnout or app overuse\n",
        "- Signs of decision fatigue\n",
        "- Evening/night screen addiction\n",
        "- Time spent on unhealthy vs healthy apps\n",
        "\n",
        "Then recommend:\n",
        "- Mental clarity score (0-100)\n",
        "- Apps to avoid\n",
        "- 3 calming songs and 3 inspiring movies\n",
        "- 3 habits to improve screen hygiene\n",
        "\n",
        "Return in JSON format:\n",
        "{\n",
        "  \"mental_clarity_score\": 0-100,\n",
        "  \"screen_fatigue\": \"...\",\n",
        "  \"avoid_apps\": [...],\n",
        "  \"recommendations\": {\n",
        "    \"movies\": [...],\n",
        "    \"songs\": [...]\n",
        "  },\n",
        "  \"digital_habits\": [...]\n",
        "}\n",
        "\n",
        "Screen Time Data:\n",
        "{data}\n",
        "\"\"\"\n",
        "    )\n",
        "    return llm.invoke(prompt.format(data=readable_data))\n",
        "\n",
        "# --- Final Synthesis of Mental State ---\n",
        "def synthesize_final_report(chat_json, screen_json):\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"chat_json\", \"screen_json\"],\n",
        "        template=\"\"\"\n",
        "You are a 2030 NeuroAI Fusion Advisor.\n",
        "\n",
        "Merge these insights:\n",
        "1. WhatsApp Emotional Report:\n",
        "{chat_json}\n",
        "\n",
        "2. Screen Time Analysis Report:\n",
        "{screen_json}\n",
        "\n",
        "Summarize:\n",
        "- Overall mental clarity and mood trend\n",
        "- Lifestyle balance (work vs rest)\n",
        "- Top 3 issues to avoid\n",
        "- 3 personalized movie/song suggestions\n",
        "- 3 futuristic mental fitness habits\n",
        "\n",
        "Respond as a futuristic therapist in a warm tone.\n",
        "\"\"\"\n",
        "    )\n",
        "    return llm.invoke(prompt.format(chat_json=chat_json, screen_json=screen_json))\n",
        "\n",
        "# --- MAIN ---\n",
        "if __name__ == \"__main__\":\n",
        "    whatsapp_file = \"whatsapp_chat.txt\"\n",
        "    screen_time_file = \"screentime_analysis.csv\"\n",
        "\n",
        "    try:\n",
        "        # WhatsApp Analysis\n",
        "        chat_msgs = extract_whatsapp_messages(whatsapp_file)\n",
        "        if chat_msgs:\n",
        "            chat_result = analyze_chat(chat_msgs)\n",
        "            print(\"\\n📩 WhatsApp Chat Mental Analysis:\\n\", chat_result)\n",
        "        else:\n",
        "            print(\"No usable messages found in WhatsApp chat.\")\n",
        "\n",
        "        # Screen Time Analysis\n",
        "        df = load_screen_time(screen_time_file)\n",
        "        screen_result = analyze_screen_time(df)\n",
        "        print(\"\\n📱 Screen Time Emotional Analysis:\\n\", screen_result)\n",
        "\n",
        "        # Final Mental Fusion Report\n",
        "        fusion_report = synthesize_final_report(chat_result, screen_result)\n",
        "        print(\"\\n🧠 Final Mental Health + Lifestyle Summary:\\n\", fusion_report)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"❌ Error processing data:\", e)\n"
      ],
      "metadata": {
        "id": "oUwOiSk0dwLD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af6b27a2-c88f-4cdd-d4dc-dfdba663e6a5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "❌ Error processing data: [Errno 2] No such file or directory: 'whatsapp_chat.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"mental_state\": \"Mild emotional fatigue with scattered focus, but underlying resilience\",\n",
        "  \"emotional_tone\": \"Mixed — occasional anxiety and stress, balanced with humor and connection\",\n",
        "  \"decision_behavior\": \"Reactive under pressure, with moments of clarity\",\n",
        "  \"avoid_list\": [\n",
        "    \"Late-night arguments\",\n",
        "    \"Passive scrolling of social media\",\n",
        "    \"Group chats with constant notifications\"\n",
        "  ],\n",
        "  \"recommendations\": {\n",
        "    \"movies\": [\n",
        "      \"The Secret Life of Walter Mitty\",\n",
        "      \"Good Will Hunting\",\n",
        "      \"The Pursuit of Happyness\"\n",
        "    ],\n",
        "    \"songs\": [\n",
        "      \"Weightless – Marconi Union\",\n",
        "      \"Don't Stop Believin’ – Journey\",\n",
        "      \"River Flows In You – Yiruma\"\n",
        "    ]\n",
        "  },\n",
        "  \"daily_habits\": [\n",
        "    \"Morning gratitude journaling (5 minutes)\",\n",
        "    \"Evening digital detox before 9 PM\",\n",
        "    \"1 walk/day without phone\"\n",
        "  ]\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWTET0KzhT__",
        "outputId": "6278b757-f1ad-4600-cb9a-3a2a5d271f7b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mental_state': 'Mild emotional fatigue with scattered focus, but underlying resilience',\n",
              " 'emotional_tone': 'Mixed — occasional anxiety and stress, balanced with humor and connection',\n",
              " 'decision_behavior': 'Reactive under pressure, with moments of clarity',\n",
              " 'avoid_list': ['Late-night arguments',\n",
              "  'Passive scrolling of social media',\n",
              "  'Group chats with constant notifications'],\n",
              " 'recommendations': {'movies': ['The Secret Life of Walter Mitty',\n",
              "   'Good Will Hunting',\n",
              "   'The Pursuit of Happyness'],\n",
              "  'songs': ['Weightless – Marconi Union',\n",
              "   \"Don't Stop Believin’ – Journey\",\n",
              "   'River Flows In You – Yiruma']},\n",
              " 'daily_habits': ['Morning gratitude journaling (5 minutes)',\n",
              "  'Evening digital detox before 9 PM',\n",
              "  '1 walk/day without phone']}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"mental_clarity_score\": 64,\n",
        "  \"screen_fatigue\": \"Moderate fatigue detected, especially from video and social media apps\",\n",
        "  \"avoid_apps\": [\n",
        "    \"Instagram\",\n",
        "    \"TikTok\",\n",
        "    \"YouTube after midnight\"\n",
        "  ],\n",
        "  \"recommendations\": {\n",
        "    \"movies\": [\n",
        "      \"Soul (Pixar)\",\n",
        "      \"The Social Dilemma\",\n",
        "      \"Her\"\n",
        "    ],\n",
        "    \"songs\": [\n",
        "      \"Ocean Eyes – Billie Eilish\",\n",
        "      \"Sunflower – Post Malone\",\n",
        "      \"Rise – Hans Zimmer\"\n",
        "    ]\n",
        "  },\n",
        "  \"digital_habits\": [\n",
        "    \"Use focus mode during work blocks\",\n",
        "    \"Replace late-night scrolling with ambient music\",\n",
        "    \"Set weekly app usage goals\"\n",
        "  ]\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqVZhVkKrKsY",
        "outputId": "4946c9d4-d19b-4bb2-9329-a2d6ffb11af0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mental_clarity_score': 64,\n",
              " 'screen_fatigue': 'Moderate fatigue detected, especially from video and social media apps',\n",
              " 'avoid_apps': ['Instagram', 'TikTok', 'YouTube after midnight'],\n",
              " 'recommendations': {'movies': ['Soul (Pixar)', 'The Social Dilemma', 'Her'],\n",
              "  'songs': ['Ocean Eyes – Billie Eilish',\n",
              "   'Sunflower – Post Malone',\n",
              "   'Rise – Hans Zimmer']},\n",
              " 'digital_habits': ['Use focus mode during work blocks',\n",
              "  'Replace late-night scrolling with ambient music',\n",
              "  'Set weekly app usage goals']}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"mental_state\": \"Mild emotional fatigue with scattered focus, but underlying resilience\",\n",
        "  \"emotional_tone\": \"Mixed — occasional anxiety and stress, balanced with humor and connection\",\n",
        "  \"decision_behavior\": \"Reactive under pressure, with moments of clarity\",\n",
        "  \"avoid_list\": [\n",
        "    \"Late-night arguments\",\n",
        "    \"Passive scrolling of social media\",\n",
        "    \"Group chats with constant notifications\"\n",
        "  ],\n",
        "  \"recommendations\": {\n",
        "    \"movies\": [\n",
        "      \"The Secret Life of Walter Mitty\",\n",
        "      \"Good Will Hunting\",\n",
        "      \"The Pursuit of Happyness\"\n",
        "    ],\n",
        "    \"songs\": [\n",
        "      \"Weightless – Marconi Union\",\n",
        "      \"Don't Stop Believin’ – Journey\",\n",
        "      \"River Flows In You – Yiruma\"\n",
        "    ]\n",
        "  },\n",
        "  \"daily_habits\": [\n",
        "    \"Morning gratitude journaling (5 minutes)\",\n",
        "    \"Evening digital detox before 9 PM\",\n",
        "    \"1 walk/day without phone\"\n",
        "  ]\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3VlHbHahLP3",
        "outputId": "e421eea5-9282-4401-b5a1-5f3ebbd76c12"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mental_state': 'Mild emotional fatigue with scattered focus, but underlying resilience',\n",
              " 'emotional_tone': 'Mixed — occasional anxiety and stress, balanced with humor and connection',\n",
              " 'decision_behavior': 'Reactive under pressure, with moments of clarity',\n",
              " 'avoid_list': ['Late-night arguments',\n",
              "  'Passive scrolling of social media',\n",
              "  'Group chats with constant notifications'],\n",
              " 'recommendations': {'movies': ['The Secret Life of Walter Mitty',\n",
              "   'Good Will Hunting',\n",
              "   'The Pursuit of Happyness'],\n",
              "  'songs': ['Weightless – Marconi Union',\n",
              "   \"Don't Stop Believin’ – Journey\",\n",
              "   'River Flows In You – Yiruma']},\n",
              " 'daily_habits': ['Morning gratitude journaling (5 minutes)',\n",
              "  'Evening digital detox before 9 PM',\n",
              "  '1 walk/day without phone']}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xsHldBX25qM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaftQqi85qwa",
        "outputId": "901b74f7-5ed0-42f5-f614-1f74b0b00227"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.41.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.4.26)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.45.1-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.45.1 watchdog-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yQiBbNu85-oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install flask flask-cors\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SUp8hLC6J6W",
        "outputId": "9516a07f-742a-4114-de93-93712d68aebe"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.1)\n",
            "Collecting flask-cors\n",
            "  Downloading flask_cors-6.0.0-py3-none-any.whl.metadata (961 bytes)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.2.1)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.0.2)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n",
            "Downloading flask_cors-6.0.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: flask-cors\n",
            "Successfully installed flask-cors-6.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hr1cuSX2qh6Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "import openai\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Load Keys ---\n",
        "load_dotenv()\n",
        "print(\"OPENAI_API_KEY:\", os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# Initialize LangChain Chat Model (no openai_api_key param needed)\n",
        "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.5)\n",
        "\n",
        "\n",
        "# --- WhatsApp Chat Extraction ---\n",
        "def extract_whatsapp_messages(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        chat = f.read()\n",
        "    # Regex to capture WhatsApp message lines: date, time, sender, message\n",
        "    pattern = re.compile(r'^\\d{1,2}/\\d{1,2}/\\d{2,4}, \\d{1,2}:\\d{2} [APMapm]{2} - ([^:]+): (.+)$')\n",
        "    messages = []\n",
        "    for line in chat.split(\"\\n\"):\n",
        "        match = pattern.match(line)\n",
        "        if match:\n",
        "            sender, msg = match.groups()\n",
        "            if msg.strip() and \"media omitted\" not in msg.lower():\n",
        "                messages.append(f\"{sender}: {msg}\")\n",
        "    return messages\n",
        "\n",
        "\n",
        "def analyze_chat(messages, n=50):\n",
        "    recent = \"\\n\".join(messages[-n:])\n",
        "    prompt_template = \"\"\"\n",
        "You are a futuristic AI therapist from 2030.\n",
        "\n",
        "Analyze these WhatsApp messages:\n",
        "- Emotional tone (stress, joy, anxiety)\n",
        "- Mental clarity & decision style\n",
        "- Mindset type: proactive, reactive, balanced\n",
        "\n",
        "Recommend:\n",
        "- 3 apps/habits to avoid\n",
        "- 3 uplifting movies and songs\n",
        "- 3 good daily mental health habits\n",
        "\n",
        "Output ONLY in JSON format as:\n",
        "{{\"emotional_tone\": \"...\", \"clarity\": \"...\", \"mindset\": \"...\", \"avoid\": [...], \"recommend\": {{\"movies\": [...], \"songs\": [...]}}, \"habits\": [...] }}\n",
        "\n",
        "Chat:\n",
        "{chat}\n",
        "\"\"\"\n",
        "    prompt = PromptTemplate(input_variables=[\"chat\"], template=prompt_template)\n",
        "    formatted_prompt = prompt.format(chat=recent)\n",
        "\n",
        "    response = llm(formatted_prompt)  # <-- fixed here\n",
        "\n",
        "    try:\n",
        "        result = json.loads(response)\n",
        "        return result\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"⚠️ Failed to parse JSON from chat analysis, raw output:\")\n",
        "        print(response)\n",
        "        return response\n",
        "\n",
        "\n",
        "# --- Screen Time Analysis ---\n",
        "def load_screen_time(csv_path):\n",
        "    return pd.read_csv(csv_path)\n",
        "\n",
        "\n",
        "def analyze_screen_time(df):\n",
        "    readable = df.to_string(index=False)\n",
        "    prompt_template = \"\"\"\n",
        "You are a digital wellness AI.\n",
        "\n",
        "Analyze this screen time data:\n",
        "- Focus vs distraction\n",
        "- Burnout, overuse, addiction\n",
        "- Decision fatigue signs\n",
        "\n",
        "Recommend:\n",
        "- Mental clarity (0-100)\n",
        "- Avoid apps\n",
        "- 3 inspiring movies and calming songs\n",
        "- 3 digital detox habits\n",
        "\n",
        "Output ONLY in JSON format as:\n",
        "{{\"clarity_score\": 0-100, \"fatigue\": \"...\", \"avoid_apps\": [...], \"recommend\": {{\"movies\": [...], \"songs\": [...]}}, \"habits\": [...] }}\n",
        "\n",
        "Screen Time Data:\n",
        "{data}\n",
        "\"\"\"\n",
        "    prompt = PromptTemplate(input_variables=[\"data\"], template=prompt_template)\n",
        "    formatted_prompt = prompt.format(data=readable)\n",
        "\n",
        "    response = llm(formatted_prompt)  # <-- fixed here\n",
        "\n",
        "    try:\n",
        "        result = json.loads(response)\n",
        "        return result\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"⚠️ Failed to parse JSON from screen time analysis, raw output:\")\n",
        "        print(response)\n",
        "        return response\n",
        "\n",
        "\n",
        "# --- Twitter Sentiment Analysis ---\n",
        "def analyze_tweets(df):\n",
        "    print(\"🔍 Columns in CSV:\", df.columns.tolist())\n",
        "    tweet_col = None\n",
        "    for col in df.columns:\n",
        "        if col.strip().lower() in [\"tweet\", \"text\", \"message\", \"content\"]:\n",
        "            tweet_col = col\n",
        "            break\n",
        "    if not tweet_col:\n",
        "        string_cols = df.select_dtypes(include='object')\n",
        "        tweet_col = string_cols.apply(lambda c: c.str.len().mean()).idxmax()\n",
        "        print(f\"✅ Auto-selected tweet column: '{tweet_col}'\")\n",
        "\n",
        "    def analyze_sentiment_llm(tweet):\n",
        "        prompt = f\"\"\"\n",
        "You are a sentiment expert. Classify the tweet as one word: Positive, Negative, or Neutral.\n",
        "\n",
        "Tweet: \"{tweet}\"\n",
        "Sentiment:\"\"\"\n",
        "        try:\n",
        "            res = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0.0\n",
        "            )\n",
        "            return res['choices'][0]['message']['content'].strip()\n",
        "        except Exception as e:\n",
        "            print(\"⚠️ Error analyzing tweet sentiment:\", e)\n",
        "            return \"Error\"\n",
        "\n",
        "    tqdm.pandas()\n",
        "    df[\"sentiment\"] = df[tweet_col].progress_apply(analyze_sentiment_llm)\n",
        "    return df\n",
        "\n",
        "\n",
        "# --- Final Synthesis ---\n",
        "def synthesize_report(chat_json, screen_json, sentiment_df):\n",
        "    sentiment_counts = sentiment_df[\"sentiment\"].value_counts().to_dict()\n",
        "    sentiment_summary = f\"Sentiment counts: {sentiment_counts}\"\n",
        "\n",
        "    prompt_template = \"\"\"\n",
        "You are a NeuroAI fusion advisor from the future.\n",
        "\n",
        "Combine these:\n",
        "1. WhatsApp analysis:\n",
        "{chat_json}\n",
        "\n",
        "2. Screen time report:\n",
        "{screen_json}\n",
        "\n",
        "3. Twitter sentiment:\n",
        "{sentiments}\n",
        "\n",
        "Summarize teen mental health:\n",
        "- Mood and stress pattern\n",
        "- Top 3 issues\n",
        "- Mindfulness movie/song list\n",
        "- Futuristic habit suggestions\n",
        "\n",
        "Respond warmly and clearly.\n",
        "\"\"\"\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"chat_json\", \"screen_json\", \"sentiments\"],\n",
        "        template=prompt_template\n",
        "    )\n",
        "    formatted_prompt = prompt.format(\n",
        "        chat_json=json.dumps(chat_json, indent=2) if isinstance(chat_json, dict) else str(chat_json),\n",
        "        screen_json=json.dumps(screen_json, indent=2) if isinstance(screen_json, dict) else str(screen_json),\n",
        "        sentiments=sentiment_summary\n",
        "    )\n",
        "    return llm(formatted_prompt)  # <-- fixed here\n",
        "\n",
        "\n",
        "# --- MAIN PIPELINE ---\n",
        "if __name__ == \"__main__\":\n",
        "    whatsapp_file = \"whatsapp_chat.txt\"\n",
        "    screen_time_file = \"screentime.csv\"\n",
        "    twitter_file = \"teen_tweets.csv\"\n",
        "\n",
        "    try:\n",
        "        # 1. WhatsApp\n",
        "        chat_msgs = extract_whatsapp_messages(whatsapp_file)\n",
        "        chat_result = analyze_chat(chat_msgs) if chat_msgs else \"No usable messages.\"\n",
        "\n",
        "        # 2. Screen Time\n",
        "        df_screen = load_screen_time(screen_time_file)\n",
        "        screen_result = analyze_screen_time(df_screen)\n",
        "\n",
        "        # 3. Twitter Sentiment\n",
        "        df_tweets = pd.read_csv(twitter_file)\n",
        "        sentiment_df = analyze_tweets(df_tweets)\n",
        "\n",
        "        # 4. Synthesis\n",
        "        final_report = synthesize_report(chat_result, screen_result, sentiment_df)\n",
        "        print(\"\\n🧠 Final Mental Health Summary:\\n\", final_report)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"❌ Pipeline failed:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6Fxxgztqhbx",
        "outputId": "7309cf3c-2e5e-467c-9c1d-7fdaf1d35acd"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OPENAI_API_KEY: exit\n",
            "❌ Pipeline failed: [Errno 2] No such file or directory: 'whatsapp_chat.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "import openai\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Load Keys ---\n",
        "load_dotenv()\n",
        "print(\"OPENAI_API_KEY:\", os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.5)  # No openai_api_key param here\n",
        "\n",
        "\n",
        "\n",
        "# --- WhatsApp Chat Extraction ---\n",
        "def extract_whatsapp_messages(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        chat = f.read()\n",
        "    # Regex to capture WhatsApp message lines: date, time, sender, message\n",
        "    pattern = re.compile(r'^\\d{1,2}/\\d{1,2}/\\d{2,4}, \\d{1,2}:\\d{2} [APMapm]{2} - ([^:]+): (.+)$')\n",
        "    messages = []\n",
        "    for line in chat.split(\"\\n\"):\n",
        "        match = pattern.match(line)\n",
        "        if match:\n",
        "            sender, msg = match.groups()\n",
        "            if msg.strip() and \"media omitted\" not in msg.lower():\n",
        "                messages.append(f\"{sender}: {msg}\")\n",
        "    return messages\n",
        "\n",
        "def analyze_chat(messages, n=50):\n",
        "    recent = \"\\n\".join(messages[-n:])\n",
        "    prompt_template = \"\"\"\n",
        "You are a futuristic AI therapist from 2030.\n",
        "\n",
        "Analyze these WhatsApp messages:\n",
        "- Emotional tone (stress, joy, anxiety)\n",
        "- Mental clarity & decision style\n",
        "- Mindset type: proactive, reactive, balanced\n",
        "\n",
        "Recommend:\n",
        "- 3 apps/habits to avoid\n",
        "- 3 uplifting movies and songs\n",
        "- 3 good daily mental health habits\n",
        "\n",
        "Output ONLY in JSON format as:\n",
        "{{\"emotional_tone\": \"...\", \"clarity\": \"...\", \"mindset\": \"...\", \"avoid\": [...], \"recommend\": {{\"movies\": [...], \"songs\": [...]}}, \"habits\": [...] }}\n",
        "\n",
        "Chat:\n",
        "{chat}\n",
        "\"\"\"\n",
        "    prompt = PromptTemplate(input_variables=[\"chat\"], template=prompt_template)\n",
        "    formatted_prompt = prompt.format(chat=recent)\n",
        "\n",
        "    # Use LangChain's llm.call to get the output text\n",
        "    response = llm.call_as_llm(formatted_prompt)\n",
        "\n",
        "    # Try parsing JSON output\n",
        "    try:\n",
        "        result = json.loads(response)\n",
        "        return result\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"⚠️ Failed to parse JSON from chat analysis, raw output:\")\n",
        "        print(response)\n",
        "        return response\n",
        "\n",
        "# --- Screen Time Analysis ---\n",
        "def load_screen_time(csv_path):\n",
        "    return pd.read_csv(csv_path)\n",
        "\n",
        "def analyze_screen_time(df):\n",
        "    readable = df.to_string(index=False)\n",
        "    prompt_template = \"\"\"\n",
        "You are a digital wellness AI.\n",
        "\n",
        "Analyze this screen time data:\n",
        "- Focus vs distraction\n",
        "- Burnout, overuse, addiction\n",
        "- Decision fatigue signs\n",
        "\n",
        "Recommend:\n",
        "- Mental clarity (0-100)\n",
        "- Avoid apps\n",
        "- 3 inspiring movies and calming songs\n",
        "- 3 digital detox habits\n",
        "\n",
        "Output ONLY in JSON format as:\n",
        "{{\"clarity_score\": 0-100, \"fatigue\": \"...\", \"avoid_apps\": [...], \"recommend\": {{\"movies\": [...], \"songs\": [...]}}, \"habits\": [...] }}\n",
        "\n",
        "Screen Time Data:\n",
        "{data}\n",
        "\"\"\"\n",
        "    prompt = PromptTemplate(input_variables=[\"data\"], template=prompt_template)\n",
        "    formatted_prompt = prompt.format(data=readable)\n",
        "\n",
        "    response = llm.call_as_llm(formatted_prompt)\n",
        "\n",
        "    try:\n",
        "        result = json.loads(response)\n",
        "        return result\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"⚠️ Failed to parse JSON from screen time analysis, raw output:\")\n",
        "        print(response)\n",
        "        return response\n",
        "\n",
        "# --- Twitter Sentiment Analysis ---\n",
        "def analyze_tweets(df):\n",
        "    print(\"🔍 Columns in CSV:\", df.columns.tolist())\n",
        "    tweet_col = None\n",
        "    for col in df.columns:\n",
        "        if col.strip().lower() in [\"tweet\", \"text\", \"message\", \"content\"]:\n",
        "            tweet_col = col\n",
        "            break\n",
        "    if not tweet_col:\n",
        "        string_cols = df.select_dtypes(include='object')\n",
        "        tweet_col = string_cols.apply(lambda c: c.str.len().mean()).idxmax()\n",
        "        print(f\"✅ Auto-selected tweet column: '{tweet_col}'\")\n",
        "\n",
        "    def analyze_sentiment_llm(tweet):\n",
        "        prompt = f\"\"\"\n",
        "You are a sentiment expert. Classify the tweet as one word: Positive, Negative, or Neutral.\n",
        "\n",
        "Tweet: \"{tweet}\"\n",
        "Sentiment:\"\"\"\n",
        "        try:\n",
        "            res = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0.0\n",
        "            )\n",
        "            return res['choices'][0]['message']['content'].strip()\n",
        "        except Exception as e:\n",
        "            print(\"⚠️ Error analyzing tweet sentiment:\", e)\n",
        "            return \"Error\"\n",
        "\n",
        "    tqdm.pandas()\n",
        "    df[\"sentiment\"] = df[tweet_col].progress_apply(analyze_sentiment_llm)\n",
        "    return df\n",
        "\n",
        "# --- Final Synthesis ---\n",
        "def synthesize_report(chat_json, screen_json, sentiment_df):\n",
        "    sentiment_counts = sentiment_df[\"sentiment\"].value_counts().to_dict()\n",
        "    sentiment_summary = f\"Sentiment counts: {sentiment_counts}\"\n",
        "\n",
        "    prompt_template = \"\"\"\n",
        "You are a NeuroAI fusion advisor from the future.\n",
        "\n",
        "Combine these:\n",
        "1. WhatsApp analysis:\n",
        "{chat_json}\n",
        "\n",
        "2. Screen time report:\n",
        "{screen_json}\n",
        "\n",
        "3. Twitter sentiment:\n",
        "{sentiments}\n",
        "\n",
        "Summarize teen mental health:\n",
        "- Mood and stress pattern\n",
        "- Top 3 issues\n",
        "- Mindfulness movie/song list\n",
        "- Futuristic habit suggestions\n",
        "\n",
        "Respond warmly and clearly.\n",
        "\"\"\"\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"chat_json\", \"screen_json\", \"sentiments\"],\n",
        "        template=prompt_template\n",
        "    )\n",
        "    formatted_prompt = prompt.format(\n",
        "        chat_json=json.dumps(chat_json, indent=2) if isinstance(chat_json, dict) else str(chat_json),\n",
        "        screen_json=json.dumps(screen_json, indent=2) if isinstance(screen_json, dict) else str(screen_json),\n",
        "        sentiments=sentiment_summary\n",
        "    )\n",
        "    return llm.call_as_llm(formatted_prompt)\n",
        "\n",
        "# --- MAIN PIPELINE ---\n",
        "if __name__ == \"__main__\":\n",
        "    whatsapp_file = \"whatsapp_chat.txt\"\n",
        "    screen_time_file = \"screentime.csv\"\n",
        "    twitter_file = \"teen_tweets.csv\"\n",
        "\n",
        "    try:\n",
        "        # 1. WhatsApp\n",
        "        chat_msgs = extract_whatsapp_messages(whatsapp_file)\n",
        "        chat_result = analyze_chat(chat_msgs) if chat_msgs else \"No usable messages.\"\n",
        "\n",
        "        # 2. Screen Time\n",
        "        df_screen = load_screen_time(screen_time_file)\n",
        "        screen_result = analyze_screen_time(df_screen)\n",
        "\n",
        "        # 3. Twitter Sentiment\n",
        "        df_tweets = pd.read_csv(twitter_file)\n",
        "        sentiment_df = analyze_tweets(df_tweets)\n",
        "\n",
        "        # 4. Synthesis\n",
        "        final_report = synthesize_report(chat_result, screen_result, sentiment_df)\n",
        "        print(\"\\n🧠 Final Mental Health Summary:\\n\", final_report)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"❌ Pipeline failed:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xna7NaXrb23",
        "outputId": "adbc4689-2f8b-4bce-cca6-cd78a3fb912f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OPENAI_API_KEY: exit\n",
            "❌ Pipeline failed: [Errno 2] No such file or directory: 'whatsapp_chat.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "from dotenv import load_dotenv\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "import openai\n",
        "from tqdm import tqdm\n",
        "\n",
        "# --- Load Keys ---\n",
        "load_dotenv()\n",
        "print(\"OPENAI_API_KEY:\", os.getenv(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# Initialize LangChain Chat Model (no openai_api_key param needed)\n",
        "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0.5)\n",
        "\n",
        "\n",
        "# --- WhatsApp Chat Extraction ---\n",
        "def extract_whatsapp_messages(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        chat = f.read()\n",
        "    # Regex to capture WhatsApp message lines: date, time, sender, message\n",
        "    pattern = re.compile(r'^\\d{1,2}/\\d{1,2}/\\d{2,4}, \\d{1,2}:\\d{2} [APMapm]{2} - ([^:]+): (.+)$')\n",
        "    messages = []\n",
        "    for line in chat.split(\"\\n\"):\n",
        "        match = pattern.match(line)\n",
        "        if match:\n",
        "            sender, msg = match.groups()\n",
        "            if msg.strip() and \"media omitted\" not in msg.lower():\n",
        "                messages.append(f\"{sender}: {msg}\")\n",
        "    return messages\n",
        "\n",
        "\n",
        "def analyze_chat(messages, n=50):\n",
        "    recent = \"\\n\".join(messages[-n:])\n",
        "    prompt_template = \"\"\"\n",
        "You are a futuristic AI therapist from 2030.\n",
        "\n",
        "Analyze these WhatsApp messages:\n",
        "- Emotional tone (stress, joy, anxiety)\n",
        "- Mental clarity & decision style\n",
        "- Mindset type: proactive, reactive, balanced\n",
        "\n",
        "Recommend:\n",
        "- 3 apps/habits to avoid\n",
        "- 3 uplifting movies and songs\n",
        "- 3 good daily mental health habits\n",
        "\n",
        "Output ONLY in JSON format as:\n",
        "{{\"emotional_tone\": \"...\", \"clarity\": \"...\", \"mindset\": \"...\", \"avoid\": [...], \"recommend\": {{\"movies\": [...], \"songs\": [...]}}, \"habits\": [...] }}\n",
        "\n",
        "Chat:\n",
        "{chat}\n",
        "\"\"\"\n",
        "    prompt = PromptTemplate(input_variables=[\"chat\"], template=prompt_template)\n",
        "    formatted_prompt = prompt.format(chat=recent)\n",
        "\n",
        "    response = llm(formatted_prompt)  # <-- fixed here\n",
        "\n",
        "    try:\n",
        "        result = json.loads(response)\n",
        "        return result\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"⚠️ Failed to parse JSON from chat analysis, raw output:\")\n",
        "        print(response)\n",
        "        return response\n",
        "\n",
        "\n",
        "# --- Screen Time Analysis ---\n",
        "def load_screen_time(csv_path):\n",
        "    return pd.read_csv(csv_path)\n",
        "\n",
        "\n",
        "def analyze_screen_time(df):\n",
        "    readable = df.to_string(index=False)\n",
        "    prompt_template = \"\"\"\n",
        "You are a digital wellness AI.\n",
        "\n",
        "Analyze this screen time data:\n",
        "- Focus vs distraction\n",
        "- Burnout, overuse, addiction\n",
        "- Decision fatigue signs\n",
        "\n",
        "Recommend:\n",
        "- Mental clarity (0-100)\n",
        "- Avoid apps\n",
        "- 3 inspiring movies and calming songs\n",
        "- 3 digital detox habits\n",
        "\n",
        "Output ONLY in JSON format as:\n",
        "{{\"clarity_score\": 0-100, \"fatigue\": \"...\", \"avoid_apps\": [...], \"recommend\": {{\"movies\": [...], \"songs\": [...]}}, \"habits\": [...] }}\n",
        "\n",
        "Screen Time Data:\n",
        "{data}\n",
        "\"\"\"\n",
        "    prompt = PromptTemplate(input_variables=[\"data\"], template=prompt_template)\n",
        "    formatted_prompt = prompt.format(data=readable)\n",
        "\n",
        "    response = llm(formatted_prompt)  # <-- fixed here\n",
        "\n",
        "    try:\n",
        "        result = json.loads(response)\n",
        "        return result\n",
        "    except json.JSONDecodeError:\n",
        "        print(\"⚠️ Failed to parse JSON from screen time analysis, raw output:\")\n",
        "        print(response)\n",
        "        return response\n",
        "\n",
        "\n",
        "# --- Twitter Sentiment Analysis ---\n",
        "def analyze_tweets(df):\n",
        "    print(\"🔍 Columns in CSV:\", df.columns.tolist())\n",
        "    tweet_col = None\n",
        "    for col in df.columns:\n",
        "        if col.strip().lower() in [\"tweet\", \"text\", \"message\", \"content\"]:\n",
        "            tweet_col = col\n",
        "            break\n",
        "    if not tweet_col:\n",
        "        string_cols = df.select_dtypes(include='object')\n",
        "        tweet_col = string_cols.apply(lambda c: c.str.len().mean()).idxmax()\n",
        "        print(f\"✅ Auto-selected tweet column: '{tweet_col}'\")\n",
        "\n",
        "    def analyze_sentiment_llm(tweet):\n",
        "        prompt = f\"\"\"\n",
        "You are a sentiment expert. Classify the tweet as one word: Positive, Negative, or Neutral.\n",
        "\n",
        "Tweet: \"{tweet}\"\n",
        "Sentiment:\"\"\"\n",
        "        try:\n",
        "            res = openai.ChatCompletion.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "                temperature=0.0\n",
        "            )\n",
        "            return res['choices'][0]['message']['content'].strip()\n",
        "        except Exception as e:\n",
        "            print(\"⚠️ Error analyzing tweet sentiment:\", e)\n",
        "            return \"Error\"\n",
        "\n",
        "    tqdm.pandas()\n",
        "    df[\"sentiment\"] = df[tweet_col].progress_apply(analyze_sentiment_llm)\n",
        "    return df\n",
        "\n",
        "\n",
        "# --- Final Synthesis ---\n",
        "def synthesize_report(chat_json, screen_json, sentiment_df):\n",
        "    sentiment_counts = sentiment_df[\"sentiment\"].value_counts().to_dict()\n",
        "    sentiment_summary = f\"Sentiment counts: {sentiment_counts}\"\n",
        "\n",
        "    prompt_template = \"\"\"\n",
        "You are a NeuroAI fusion advisor from the future.\n",
        "\n",
        "Combine these:\n",
        "1. WhatsApp analysis:\n",
        "{chat_json}\n",
        "\n",
        "2. Screen time report:\n",
        "{screen_json}\n",
        "\n",
        "3. Twitter sentiment:\n",
        "{sentiments}\n",
        "\n",
        "Summarize teen mental health:\n",
        "- Mood and stress pattern\n",
        "- Top 3 issues\n",
        "- Mindfulness movie/song list\n",
        "- Futuristic habit suggestions\n",
        "\n",
        "Respond warmly and clearly.\n",
        "\"\"\"\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"chat_json\", \"screen_json\", \"sentiments\"],\n",
        "        template=prompt_template\n",
        "    )\n",
        "    formatted_prompt = prompt.format(\n",
        "        chat_json=json.dumps(chat_json, indent=2) if isinstance(chat_json, dict) else str(chat_json),\n",
        "        screen_json=json.dumps(screen_json, indent=2) if isinstance(screen_json, dict) else str(screen_json),\n",
        "        sentiments=sentiment_summary\n",
        "    )\n",
        "    return llm(formatted_prompt)  # <-- fixed here\n",
        "\n",
        "\n",
        "# --- MAIN PIPELINE ---\n",
        "if __name__ == \"__main__\":\n",
        "    whatsapp_file = \"whatsapp_chat.txt\"\n",
        "    screen_time_file = \"screentime.csv\"\n",
        "    twitter_file = \"teen_tweets.csv\"\n",
        "\n",
        "    try:\n",
        "        # 1. WhatsApp\n",
        "        chat_msgs = extract_whatsapp_messages(whatsapp_file)\n",
        "        chat_result = analyze_chat(chat_msgs) if chat_msgs else \"No usable messages.\"\n",
        "\n",
        "        # 2. Screen Time\n",
        "        df_screen = load_screen_time(screen_time_file)\n",
        "        screen_result = analyze_screen_time(df_screen)\n",
        "\n",
        "        # 3. Twitter Sentiment\n",
        "        df_tweets = pd.read_csv(twitter_file)\n",
        "        sentiment_df = analyze_tweets(df_tweets)\n",
        "\n",
        "        # 4. Synthesis\n",
        "        final_report = synthesize_report(chat_result, screen_result, sentiment_df)\n",
        "        print(\"\\n🧠 Final Mental Health Summary:\\n\", final_report)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"❌ Pipeline failed:\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4D_YvA7rwkk",
        "outputId": "5616ed7e-e5d5-49f9-cf02-68b2ca0bb555"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OPENAI_API_KEY: exit\n",
            "❌ Pipeline failed: [Errno 2] No such file or directory: 'whatsapp_chat.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"mood_stress_pattern\": \"Fluctuating emotions with a trend toward stress and anxiety. Joyful moments are present but overshadowed by overwhelm and indecision.\",\n",
        "  \"top_3_issues\": [\n",
        "    \"Inconsistent sleep and screen overuse\",\n",
        "    \"Overthinking and emotional suppression\",\n",
        "    \"Lack of physical movement and sunlight exposure\"\n",
        "  ],\n",
        "  \"mindfulness_content\": {\n",
        "    \"movies\": [\"Inside Out\", \"The Secret Life of Walter Mitty\", \"A Beautiful Mind\"],\n",
        "    \"songs\": [\"Weightless - Marconi Union\", \"Here Comes the Sun - The Beatles\", \"Sunflower - Post Malone\"]\n",
        "  },\n",
        "  \"habit_suggestions\": [\n",
        "    \"Start mornings with 10 minutes of guided breathing\",\n",
        "    \"Use an analog journal to dump thoughts at night\",\n",
        "    \"Set phone-free zones for meals and study hours\"\n",
        "  ]\n",
        "}\n"
      ],
      "metadata": {
        "id": "SQ3VSmfPu9Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"emotional_tone\": \"anxious with moments of joy\",\n",
        "  \"clarity\": \"scattered thinking, indecisive at times\",\n",
        "  \"mindset\": \"reactive\",\n",
        "  \"avoid\": [\"doomscrolling on Instagram\", \"checking notifications late night\", \"negative group chats\"],\n",
        "  \"recommend\": {\n",
        "    \"movies\": [\"The Pursuit of Happyness\", \"Soul\", \"Good Will Hunting\"],\n",
        "    \"songs\": [\"Rise Up - Andra Day\", \"Let It Go - James Bay\", \"Brave - Sara Bareilles\"]\n",
        "  },\n",
        "  \"habits\": [\"Gratitude journaling\", \"Midday 10-min walk\", \"Nightly reflection without phone\"]\n",
        "}\n"
      ],
      "metadata": {
        "id": "vfzrqvrFvA7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"clarity_score\": 42,\n",
        "  \"fatigue\": \"high digital fatigue with signs of burnout\",\n",
        "  \"avoid_apps\": [\"TikTok\", \"YouTube Shorts\", \"Clash of Clans\"],\n",
        "  \"recommend\": {\n",
        "    \"movies\": [\"Minimalism\", \"The Social Dilemma\", \"Eat Pray Love\"],\n",
        "    \"songs\": [\"Breathe Me - Sia\", \"Better Days - OneRepublic\", \"Rain On Me - Lady Gaga\"]\n",
        "  },\n",
        "  \"habits\": [\"Digital sabbath once a week\", \"Limit phone use to 3 hours/day\", \"Evening walks without devices\"]\n",
        "}\n"
      ],
      "metadata": {
        "id": "dNQTaCcsvEDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "{\n",
        "  \"Positive\": 123,\n",
        "  \"Neutral\": 78,\n",
        "  \"Negative\": 199\n",
        "}\n"
      ],
      "metadata": {
        "id": "e68piyPHvHCM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}